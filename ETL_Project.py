# -*- coding: utf-8 -*-
"""ETL_project_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TgE6HYtpjEAgllrjz3J1CxkWD9u48-Cm
"""

import glob                       #helps in selecting files
import pandas as pd        #helps in processing files
from datetime import datetime

# to get file using Url
!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip

!unzip source.zip

logfile = 'logfile.txt'                    # all event,steps will be stored in logfile
targetfile = "transformed_data.csv"        # all transformed data will de stored in this file

# i have many some files with same extention so i used function to loop
def extract_from_csv (sourcefile) :
    df = pd.read_csv(sourcefile)
    return df

def extract_from_json (sourcefile) :
    df =pd.read_json(sourcefile,lines=True)
    return df

def extract_from_xml (sourcefile):
    df=pd.read_xml(sourcefile)
    return df

# if you check files you will find out that all have the same columns so :
def extract():


  #EXTRACT ALL CSV FILES
  extracted_data = pd.DataFrame(columns = ["name","height","weight"])
  for csvfile in glob.glob("*.csv"):
    extracted_data = pd.concat([extracted_data,extract_from_csv(csvfile)],ignore_index=True)


  #EXTRACT ALL JSON FILES
  for jsonfile in glob.glob("*.json"):
    extracted_data =pd.concat([extracted_data,extract_from_json(jsonfile)],ignore_index=True)

  #EXTRACT ALL XML FILES
  for xmlfile in glob.glob("*.xml"):
    extracted_data =pd.concat([extracted_data,extract_from_xml(xmlfile)],ignore_index=True)


  return extracted_data

E=extract()
E

def transform(data):

  #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)
  data["height"]=data["height"]=round(data.height*.0254,2)

  #Convert pounds to kilograms and round off to two decimals
  data["weight"]=round(data.weight*.453592,2)

  return data

transform(E)

def load(targetfile,data_to_load):
  data_to_load.to_csv(targetfile)

load(targetfile,E)

def log(message):
  timestamp_format = '%Y-%m-%d %H:%M:%S'      # Year-Monthname-Day-Hour-Minute-Second
  now = datetime.now()        # get current timestamp
  timestamp = now.strftime(timestamp_format)
  with open("logfile.txt","a") as f:
    f.write(timestamp + ',' + message + '\n')

log("ETL Job Started")



log("Extract phase Started")
extracted_data = extract()
log("Extract phase Ended")
extracted_data

log("Transform phase Started")
transformed_data = transform(extracted_data)
log("Transform phase Ended")
transformed_data.head()

log("Load phase Started")
load(targetfile,transformed_data)
log("Load phase Ended")